#!/usr/bin/env python3
"""
Temporal Pipeline CLI - –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –Ω–∞ Typer
"""

import asyncio
import json
import uuid
from datetime import UTC, datetime
from pathlib import Path
from typing import Annotated

import typer
import yaml
from rich import print as rprint
from rich.console import Console
from rich.panel import Panel
from rich.progress import (
    BarColumn,
    Progress,
    SpinnerColumn,
    TextColumn,
    TimeElapsedColumn,
)
from rich.prompt import Confirm
from rich.syntax import Syntax
from rich.table import Table
from rich.tree import Tree

from core.component import PluginRegistry
from core.temporal.activities import (
    cleanup_pipeline_data_activity,
    execute_stage_activity,
    validate_pipeline_activity,
)
from core.temporal.interfaces import PipelineExecutionResult
from core.temporal.scheduled_workflow import ScheduledPipelineWorkflow
from core.temporal.workflow import DataPipelineWorkflow
from core.yaml_loader import YAMLConfigParser
from core.yaml_loader.interfaces import PipelineConfig

console = Console()
app = typer.Typer(
    name="temporal-pipeline",
    help="üöÄ –ú–æ—â–Ω—ã–π ETL —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ —Å Temporal.io –∏ plugin –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π",
    add_completion=False,
    rich_markup_mode="rich",
)

# –ü–æ–¥–∫–æ–º–∞–Ω–¥—ã
plugin_app = typer.Typer(help="üîå –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–ª–∞–≥–∏–Ω–∞–º–∏")
pipeline_app = typer.Typer(help="‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞–º–∏")
worker_app = typer.Typer(help="üë∑ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Temporal Workers")

app.add_typer(plugin_app, name="plugins")
app.add_typer(pipeline_app, name="pipeline")
app.add_typer(worker_app, name="worker")


@app.command()
def version() -> None:
    """üìã –ü–æ–∫–∞–∑–∞—Ç—å –≤–µ—Ä—Å–∏—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    rprint("[bold blue]Temporal Pipeline[/bold blue] [green]v1.0.0[/green]")
    rprint("üèóÔ∏è  ETL —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è")


@pipeline_app.command("run")
def run_pipeline(
    config_path: Annotated[
        Path, typer.Argument(help="–ü—É—Ç—å –∫ YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏", exists=True)
    ],
    dry_run: Annotated[
        bool, typer.Option("--dry-run", help="–¢–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è –±–µ–∑ –∑–∞–ø—É—Å–∫–∞")
    ] = False,
    env_file: Annotated[
        Path | None, typer.Option("--env-file", help="–ü—É—Ç—å –∫ .env —Ñ–∞–π–ª—É")
    ] = None,
    temporal_host: Annotated[
        str, typer.Option("--host", help="–ê–¥—Ä–µ—Å Temporal —Å–µ—Ä–≤–µ—Ä–∞")
    ] = "localhost:7233",
    namespace: Annotated[
        str, typer.Option("--namespace", help="Temporal namespace")
    ] = "default",
    run_id: Annotated[
        str | None, typer.Option("--run-id", help="–ö–∞—Å—Ç–æ–º–Ω—ã–π run ID")
    ] = None,
    wait: Annotated[
        bool,
        typer.Option("--wait/--no-wait", help="–ñ–¥–∞—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞"),
    ] = True,
    verbose: Annotated[
        bool, typer.Option("--verbose", "-v", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥")
    ] = False,
) -> None:
    """üéØ –ó–∞–ø—É—Å—Ç–∏—Ç—å ETL –ø–∞–π–ø–ª–∞–π–Ω"""
    asyncio.run(
        _run_pipeline_async(
            config_path,
            dry_run,
            env_file,
            temporal_host,
            namespace,
            run_id,
            wait,
            verbose,
        )
    )


async def _run_pipeline_async(
    config_path: Path,
    dry_run: bool,
    env_file: Path | None,
    temporal_host: str,
    namespace: str,
    run_id: str | None,
    wait: bool,
    verbose: bool,
) -> None:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    from temporalio.client import Client
    from temporalio.contrib.pydantic import pydantic_data_converter

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if env_file:
        _load_env_file(env_file)

    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TimeElapsedColumn(),
            console=console,
        ) as progress:
            # –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            task1 = progress.add_task(
                "üìã –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...", total=None
            )
            parser = YAMLConfigParser()
            pipeline_config = parser.parse_file(config_path)
            progress.advance(task1)
            progress.update(task1, description="‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–ª–∞–≥–∏–Ω–æ–≤
            task2 = progress.add_task(
                "üîå –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–ª–∞–≥–∏–Ω–æ–≤...", total=len(pipeline_config.stages)
            )
            registry = PluginRegistry()
            await registry.initialize()

            validation_errors = []
            for stage_name, stage_config in pipeline_config.stages.items():
                component_info = registry.get_plugin_info(
                    stage_config.stage, stage_config.component
                )
                if not component_info:
                    available = registry.list_plugins(stage_config.stage)
                    error_msg = (
                        f"–°—Ç–∞–¥–∏—è '{stage_name}': "
                        f"–∫–æ–º–ø–æ–Ω–µ–Ω—Ç '{stage_config.component}' "
                        f"—Ç–∏–ø–∞ '{stage_config.stage}' –Ω–µ –Ω–∞–π–¥–µ–Ω. "
                        f"–î–æ—Å—Ç—É–ø–Ω—ã–µ: {available.get(stage_config.stage, [])}"
                    )
                    validation_errors.append(error_msg)
                progress.advance(task2)

            if validation_errors:
                progress.update(
                    task2, description="‚ùå –ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"
                )
                for error in validation_errors:
                    rprint(f"[red]‚ùå {error}[/red]")
                raise typer.Exit(1)

            progress.update(task2, description="‚úÖ –í—Å–µ –ø–ª–∞–≥–∏–Ω—ã –Ω–∞–π–¥–µ–Ω—ã")

            _display_pipeline_info(pipeline_config)

            if dry_run:
                rprint(
                    "\nüîç [bold green]Dry run –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ![/bold green]"
                )
                _display_pipeline_stats(pipeline_config)
                return

            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Temporal
            task3 = progress.add_task(
                "üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Temporal...", total=None
            )
            client = None
            try:
                client = await Client.connect(
                    temporal_host,
                    namespace=namespace,
                    data_converter=pydantic_data_converter,
                )
                progress.update(
                    task3, description="‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"
                )
            except Exception as ex:
                progress.update(task3, description="‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è")
                rprint(
                    f"[red]‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Temporal: {ex}[/red]"
                )
                rprint(
                    f"[yellow]üí° –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ "
                    f"Temporal Server –∑–∞–ø—É—â–µ–Ω "
                    f"–Ω–∞ {temporal_host}[/yellow]"
                )
                raise typer.Exit(1) from ex

            # –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
            task4 = progress.add_task("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞...", total=None)

            from core.temporal.workflow import (
                DataPipelineWorkflow,
            )

            actual_run_id = (
                run_id
                or f"cli_{datetime.now(tz=UTC).strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"  # noqa: E501
            )

            if verbose:
                rprint(f"[dim]Run ID: {actual_run_id}[/dim]")

            if wait:
                if client is None:
                    raise typer.Exit(1)

                result = await client.execute_workflow(
                    DataPipelineWorkflow.run,
                    args=[pipeline_config, actual_run_id],
                    id=f"pipeline-{actual_run_id}",
                    task_queue="pipeline-tasks",
                )

                progress.update(task4, description="‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω")
                _display_execution_results(result)

            else:
                if client is None:
                    raise typer.Exit(1)

                handle = await client.start_workflow(
                    DataPipelineWorkflow.run,
                    args=[pipeline_config, actual_run_id],
                    id=f"pipeline-{actual_run_id}",
                    task_queue="pipeline-tasks",
                )

                progress.update(task4, description="‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–ø—É—â–µ–Ω")
                rprint("[green]‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–ø—É—â–µ–Ω –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ[/green]")
                rprint(f"[blue]üÜî Workflow ID: {handle.id}[/blue]")
                rprint(f"[blue]üèÉ Run ID: {actual_run_id}[/blue]")

    except Exception as ex:
        rprint(f"[red]‚ùå –û—à–∏–±–∫–∞: {ex}[/red]")
        if verbose:
            import traceback

            rprint(f"[dim]{traceback.format_exc()}[/dim]")
        raise typer.Exit(1) from ex


@pipeline_app.command("validate")
def validate_pipeline(
    config_path: Annotated[
        Path, typer.Argument(help="–ü—É—Ç—å –∫ YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏", exists=True)
    ],
    verbose: Annotated[
        bool, typer.Option("--verbose", "-v", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥")
    ] = False,
    output_format: Annotated[
        str, typer.Option("--format", help="–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞")
    ] = "table",
) -> None:
    """‚úÖ –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    asyncio.run(_validate_config_async(config_path, verbose, output_format))


async def _validate_config_async(
    config_path: Path, verbose: bool, output_format: str
) -> None:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    try:
        parser = YAMLConfigParser()
        pipeline_config = parser.parse_file(config_path)

        registry = PluginRegistry()
        await registry.initialize()

        rprint("üîç [bold blue]–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏:[/bold blue]")

        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if output_format == "table":
            table = Table(title="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–π–ø–ª–∞–π–Ω–µ", show_header=True)
            table.add_column("–ü–∞—Ä–∞–º–µ—Ç—Ä", style="cyan", width=20)
            table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="magenta")

            table.add_row("–ù–∞–∑–≤–∞–Ω–∏–µ", pipeline_config.name)
            table.add_row("–í–µ—Ä—Å–∏—è", pipeline_config.version)
            table.add_row(
                "–û–ø–∏—Å–∞–Ω–∏–µ", pipeline_config.description or "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
            )
            table.add_row(
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞–¥–∏–π", str(len(pipeline_config.stages))
            )
            table.add_row(
                "–ú–∞–∫—Å. –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å",
                str(pipeline_config.max_parallel_stages),
            )
            table.add_row(
                "–¢–∞–π–º–∞—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é", f"{pipeline_config.default_timeout}—Å"
            )

            if pipeline_config.schedule.enabled:
                schedule_info = (
                    pipeline_config.schedule.cron
                    if pipeline_config.schedule.cron
                    else pipeline_config.schedule.interval
                )
                table.add_row("–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ", f"‚úÖ {schedule_info}")
            else:
                table.add_row("–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ", "‚ùå –û—Ç–∫–ª—é—á–µ–Ω–æ")

            console.print(table)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–¥–∏–π
        stages_table = Table(title="–°—Ç–∞–¥–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞", show_header=True)
        stages_table.add_column("–°—Ç–∞–¥–∏—è", style="cyan", width=15)
        stages_table.add_column("–¢–∏–ø", style="yellow", width=10)
        stages_table.add_column("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç", style="green", width=15)
        stages_table.add_column("–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏", style="blue", width=15)
        stages_table.add_column("–°—Ç–∞—Ç—É—Å", style="red", width=12)

        if verbose:
            stages_table.add_column("–í–µ—Ä—Å–∏—è", style="dim", width=8)
            stages_table.add_column("–û–ø–∏—Å–∞–Ω–∏–µ", style="dim")

        all_valid = True
        for stage_name, stage_config in pipeline_config.stages.items():
            component_info = registry.get_plugin_info(
                stage_config.stage, stage_config.component
            )
            status = "‚úÖ OK" if component_info else "‚ùå –ù–ï –ù–ê–ô–î–ï–ù"
            if not component_info:
                all_valid = False

            dependencies = (
                ", ".join(stage_config.depends_on)
                if stage_config.depends_on
                else "–ù–µ—Ç"
            )

            row = [
                stage_name,
                stage_config.stage,
                stage_config.component,
                dependencies,
                status,
            ]

            if verbose and component_info:
                row.extend(
                    [
                        component_info.version or "–ù/–î",
                        component_info.description or "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è",
                    ]
                )
            elif verbose:
                row.extend(["–ù/–î", "–ö–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"])

            stages_table.add_row(*row)

        console.print(stages_table)

        # –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        if verbose:
            _display_dependency_analysis(pipeline_config)

        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        if all_valid:
            rprint("\n‚úÖ [bold green]–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–Ω–∞![/bold green]")
        else:
            rprint("\n‚ùå [bold red]–ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏![/bold red]")
            raise typer.Exit(1)

    except Exception as ex:
        rprint(f"[red]‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {ex}[/red]")
        raise typer.Exit(1) from ex


@plugin_app.command("list")
def list_plugins(
    plugin_type: Annotated[
        str | None, typer.Option("--type", help="–¢–∏–ø –ø–ª–∞–≥–∏–Ω–æ–≤")
    ] = None,
    output_format: Annotated[
        str, typer.Option("--format", help="–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞")
    ] = "table",
    detailed: Annotated[
        bool, typer.Option("--detailed", "-d", help="–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    ] = False,
) -> None:
    """üîå –ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–ª–∞–≥–∏–Ω—ã"""
    asyncio.run(_list_plugins_async(plugin_type, output_format, detailed))


async def _list_plugins_async(
    plugin_type: str | None, output_format: str, detailed: bool
) -> None:
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø–ª–∞–≥–∏–Ω–æ–≤"""
    registry = PluginRegistry()
    await registry.initialize()

    all_plugins = registry.get_all_plugins()

    if plugin_type:
        if plugin_type not in all_plugins:
            rprint(f"[red]‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø–ª–∞–≥–∏–Ω–∞: {plugin_type}[/red]")
            rprint(
                f"[yellow]–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø—ã: "
                f"{', '.join(all_plugins.keys())}[/yellow]"
            )
            raise typer.Exit(1)
        all_plugins = {plugin_type: all_plugins[plugin_type]}

    if output_format == "json":
        json_output = {}
        for ptype, plugins in all_plugins.items():
            json_output[ptype] = {
                name: {
                    "name": info.name,
                    "version": info.version,
                    "description": info.description,
                    "type_module": info.type_module,
                }
                for name, info in plugins.items()
            }
        rprint(json.dumps(json_output, indent=2, ensure_ascii=False))

    elif output_format == "tree":
        tree = Tree("üîå [bold blue]–î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–ª–∞–≥–∏–Ω—ã[/bold blue]")
        for ptype, plugins in all_plugins.items():
            type_branch = tree.add(
                f"üìÇ [yellow]{ptype.upper()}[/yellow] "
                f"([dim]{len(plugins)} –ø–ª–∞–≥–∏–Ω–æ–≤[/dim])"
            )
            for name, info in plugins.items():
                plugin_info = f"[green]{name}[/green]"
                if info.version:
                    plugin_info += f" [dim]v{info.version}[/dim]"
                if info.description and detailed:
                    plugin_info += f"\n   [italic]{info.description}[/italic]"
                type_branch.add(plugin_info)
        console.print(tree)

    else:
        # Table —Ñ–æ—Ä–º–∞—Ç
        total_plugins = sum(len(plugins) for plugins in all_plugins.values())
        rprint(f"[blue]üìä –í—Å–µ–≥–æ –ø–ª–∞–≥–∏–Ω–æ–≤: {total_plugins}[/blue]\n")

        for ptype, plugins in all_plugins.items():
            if plugins:
                table = Table(title=f"üîå –ü–ª–∞–≥–∏–Ω—ã —Ç–∏–ø–∞: {ptype.upper()}")
                table.add_column("–ù–∞–∑–≤–∞–Ω–∏–µ", style="cyan", width=20)
                table.add_column("–í–µ—Ä—Å–∏—è", style="yellow", width=10)

                if detailed:
                    table.add_column("–û–ø–∏—Å–∞–Ω–∏–µ", style="green")
                    table.add_column("–ú–æ–¥—É–ª—å", style="blue", width=12)
                else:
                    table.add_column("–û–ø–∏—Å–∞–Ω–∏–µ", style="green", max_width=50)

                for name, info in plugins.items():
                    row = [
                        name,
                        info.version or "–ù/–î",
                        info.description or "–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
                    ]

                    if detailed:
                        row.append(info.type_module)

                    table.add_row(*row)

                console.print(table)
                console.print()


@pipeline_app.command("init")
def init_pipeline(
    name: Annotated[str, typer.Argument(help="–ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞")],
    template: Annotated[
        str, typer.Option("--template", "-t", help="–¢–∏–ø —à–∞–±–ª–æ–Ω–∞")
    ] = "simple",
    output: Annotated[
        Path | None,
        typer.Option("--output", "-o", help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"),
    ] = None,
    force: Annotated[
        bool,
        typer.Option("--force", "-f", help="–ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª"),
    ] = False,
    edit: Annotated[
        bool, typer.Option("--edit", help="–û—Ç–∫—Ä—ã—Ç—å –≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è")
    ] = False,
) -> None:
    """üìù –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∏–∑ —à–∞–±–ª–æ–Ω–∞"""
    _create_pipeline_template(name, template, output, force, edit)


@worker_app.command("start")
def start_worker(
    host: Annotated[
        str, typer.Option("--host", help="Temporal server address")
    ] = "localhost:7233",
    namespace: Annotated[
        str, typer.Option("--namespace", help="Temporal namespace")
    ] = "default",
    task_queue: Annotated[
        str, typer.Option("--task-queue", help="Task queue name")
    ] = "pipeline-tasks",
    max_concurrent_activities: Annotated[
        int, typer.Option("--max-activities", help="–ú–∞–∫—Å. –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π")
    ] = 10,
    max_concurrent_workflows: Annotated[
        int, typer.Option("--max-workflows", help="–ú–∞–∫—Å. –≤–æ—Ä–∫—Ñ–ª–æ—É")
    ] = 5,
) -> None:
    """‚öôÔ∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å Temporal Worker"""
    asyncio.run(
        _start_worker_async(
            host,
            namespace,
            task_queue,
            max_concurrent_activities,
            max_concurrent_workflows,
        )
    )


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏


def _load_env_file(env_file: Path) -> None:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞"""
    import os

    try:
        with open(env_file) as f:
            for line in f:
                if line.strip() and not line.startswith("#") and "=" in line:
                    key, value = line.strip().split("=", 1)
                    os.environ[key] = value.strip("\"'")
        rprint(f"[green]‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ {env_file}[/green]")
    except Exception as e:
        rprint(f"[red]‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ env —Ñ–∞–π–ª–∞: {e}[/red]")


def _display_pipeline_info(pipeline_config: PipelineConfig) -> None:
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞–π–ø–ª–∞–π–Ω–µ"""
    panel_content = """
[bold blue]–ù–∞–∑–≤–∞–Ω–∏–µ:[/bold blue] {}
[bold blue]–í–µ—Ä—Å–∏—è:[/bold blue] {}
[bold blue]–û–ø–∏—Å–∞–Ω–∏–µ:[/bold blue] {}
[bold blue]–°—Ç–∞–¥–∏–π:[/bold blue] {}
[bold blue]–ú–∞–∫—Å. –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å:[/bold blue] {}
[bold blue]–¢–∞–π–º–∞—É—Ç:[/bold blue] {}—Å
""".format(
        pipeline_config.name,
        pipeline_config.version,
        pipeline_config.description or "–ù–µ —É–∫–∞–∑–∞–Ω–æ",
        len(pipeline_config.stages),
        pipeline_config.max_parallel_stages,
        pipeline_config.default_timeout,
    )

    if pipeline_config.schedule.enabled:
        schedule_info = (
            pipeline_config.schedule.cron
            if pipeline_config.schedule.cron
            else pipeline_config.schedule.interval
        )
        panel_content += (
            f"[bold blue]–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ:[/bold blue] {schedule_info}\n"
        )

    console.print(
        Panel(
            panel_content,
            title="üöÄ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–π–ø–ª–∞–π–Ω–µ",
            border_style="green",
        )
    )


def _display_pipeline_stats(pipeline_config: PipelineConfig) -> None:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    from collections import Counter

    stage_types = Counter(
        stage.stage for stage in pipeline_config.stages.values()
    )

    stats_table = Table(title="üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞")
    stats_table.add_column("–ú–µ—Ç—Ä–∏–∫–∞", style="cyan")
    stats_table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="magenta")

    for stage_type, count in stage_types.items():
        stats_table.add_row(f"–°—Ç–∞–¥–∏–π —Ç–∏–ø–∞ {stage_type}", str(count))

    deps_count = sum(
        len(stage.depends_on) for stage in pipeline_config.stages.values()
    )
    stats_table.add_row("–í—Å–µ–≥–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π", str(deps_count))
    stats_table.add_row(
        "–ü–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è", str(len(pipeline_config.required_env_vars))
    )

    console.print(stats_table)


def _display_dependency_analysis(pipeline_config: PipelineConfig) -> None:
    """–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    rprint("\n[bold blue]üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:[/bold blue]")

    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    from core.temporal.utils.transform import (
        build_execution_order,
    )

    try:
        execution_order = build_execution_order(pipeline_config.stages)

        dep_table = Table(title="–ü–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", show_header=True)
        dep_table.add_column("–ë–∞—Ç—á", style="cyan", width=8)
        dep_table.add_column("–°—Ç–∞–¥–∏–∏", style="green")
        dep_table.add_column("–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å", style="yellow", width=15)

        for i, batch in enumerate(execution_order, 1):
            dep_table.add_row(str(i), ", ".join(batch), f"{len(batch)} —Å—Ç–∞–¥–∏–π")

        console.print(dep_table)

    except ValueError as e:
        rprint(f"[red]‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è—Ö: {e}[/red]")


def _display_execution_results(result: PipelineExecutionResult) -> None:
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""

    if result.status == "success":
        rprint("\nüéâ [bold green]–ü–∞–π–ø–ª–∞–π–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ![/bold green]")

        results_table = Table(title="üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
        results_table.add_column("–ú–µ—Ç—Ä–∏–∫–∞", style="cyan")
        results_table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="magenta")

        results_table.add_row(
            "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π", str(result.total_records_processed)
        )
        results_table.add_row(
            "–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", f"{result.total_execution_time:.2f}—Å"
        )
        if result.stage_results:
            results_table.add_row(
                "–£—Å–ø–µ—à–Ω—ã—Ö —Å—Ç–∞–¥–∏–π",
                str(
                    len(
                        [
                            s
                            for s in result.stage_results
                            if s.status == "success"
                        ]
                    )
                ),
            )
        results_table.add_row("Run ID", result.run_id)

        console.print(results_table)

        # –î–µ—Ç–∞–ª–∏ –ø–æ —Å—Ç–∞–¥–∏—è–º
        if result.stage_results:
            stages_table = Table(title="–î–µ—Ç–∞–ª–∏ –ø–æ —Å—Ç–∞–¥–∏—è–º")
            stages_table.add_column("–°—Ç–∞–¥–∏—è", style="cyan")
            stages_table.add_column("–°—Ç–∞—Ç—É—Å", style="green")
            stages_table.add_column("–ó–∞–ø–∏—Å–µ–π", style="yellow")
            stages_table.add_column("–í—Ä–µ–º—è", style="blue")

            for stage_result in result.stage_results:
                status_icon = (
                    "‚úÖ" if stage_result.status == "success" else "‚ùå"
                )
                stages_table.add_row(
                    stage_result.stage_name,
                    f"{status_icon} {stage_result.status}",
                    str(stage_result.records_processed),
                    f"{stage_result.execution_time:.2f}—Å",
                )

            console.print(stages_table)
    else:
        rprint("\n‚ùå [bold red]–ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π![/bold red]")
        if result.error_message:
            rprint(f"üí• [red]–û—à–∏–±–∫–∞: {result.error_message}[/red]")


def _create_pipeline_template(
    name: str, template: str, output: Path | None, force: bool, edit: bool
) -> None:
    """–°–æ–∑–¥–∞–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    templates = {
        "simple": {
            "name": name,
            "description": f"–ü—Ä–æ—Å—Ç–æ–π ETL –ø–∞–π–ø–ª–∞–π–Ω: {name}",
            "version": "1.0.0",
            "author": "Generated by temporal-pipeline CLI",
            "tags": ["etl", "simple"],
            "schedule": {"enabled": False},
            "default_resilience": {
                "max_attempts": 3,
                "initial_delay": 1.0,
                "backoff_multiplier": 2.0,
                "retry_policy": "exponential_backoff",
            },
            "stages": {
                "extract_data": {
                    "stage": "extract",
                    "component": "csv_extract",
                    "component_config": {
                        "source_config": {
                            "path": "${SOURCE_CSV_PATH}",
                            "encoding": "utf-8",
                        },
                        "delimiter": ",",
                        "has_header": True,
                    },
                },
                "load_data": {
                    "stage": "load",
                    "component": "postgres_load",
                    "depends_on": ["extract_data"],
                    "component_config": {
                        "connection_config": {"uri": "${TARGET_DATABASE_URL}"},
                        "target_table": "target_table",
                        "target_schema": "public",
                        "if_exists": "replace",
                    },
                },
            },
            "required_env_vars": ["SOURCE_CSV_PATH", "TARGET_DATABASE_URL"],
            "max_parallel_stages": 2,
        },
        "api_to_db": {
            "name": name,
            "description": f"ETL –ø–∞–π–ø–ª–∞–π–Ω API -> "
            f"Transform -> "
            f"Database: {name}",
            "version": "1.0.0",
            "schedule": {
                "enabled": True,
                "cron": "0 */6 * * *",  # –ö–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
                "timezone": "UTC",
            },
            "stages": {
                "extract_api_data": {
                    "stage": "extract",
                    "component": "http_extract",
                    "component_config": {
                        "url": "${API_ENDPOINT}",
                        "method": "GET",
                        "auth_config": {
                            "auth_type": "bearer",
                            "bearer_token": "${API_TOKEN}",
                        },
                        "response_format": "json",
                        "json_data_path": "data",
                    },
                },
                "transform_data": {
                    "stage": "transform",
                    "component": "json_transform",
                    "depends_on": ["extract_api_data"],
                    "component_config": {
                        "filter_conditions": ['pl.col("status") == "active"'],
                        "add_metadata": True,
                    },
                },
                "load_to_database": {
                    "stage": "load",
                    "component": "postgres_load",
                    "depends_on": ["transform_data"],
                    "component_config": {
                        "connection_config": {"uri": "${DATABASE_URL}"},
                        "target_table": f"{name}_data",
                        "target_schema": "public",
                        "if_exists": "upsert",
                        "upsert_config": {"conflict_columns": ["id"]},
                    },
                },
            },
            "required_env_vars": ["API_ENDPOINT", "API_TOKEN", "DATABASE_URL"],
        },
        "complex": {
            "name": name,
            "description": f"–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π multi-source ETL –ø–∞–π–ø–ª–∞–π–Ω: {name}",
            "version": "1.0.0",
            "schedule": {
                "enabled": True,
                "cron": "0 2 * * *",
                "timezone": "UTC",
            },
            "default_resilience": {
                "max_attempts": 5,
                "initial_delay": 2.0,
                "backoff_multiplier": 2.0,
                "retry_policy": "exponential_backoff",
                "circuit_breaker_enabled": True,
            },
            "stages": {
                "extract_users": {
                    "stage": "extract",
                    "component": "http_extract",
                    "component_config": {
                        "url": "${USERS_API_URL}",
                        "auth_config": {
                            "auth_type": "bearer",
                            "bearer_token": "${API_TOKEN}",
                        },
                        "pagination_config": {
                            "pagination_type": "page",
                            "max_pages": 100,
                        },
                    },
                },
                "extract_orders": {
                    "stage": "extract",
                    "component": "sql_extract",
                    "component_config": {
                        "query": "SELECT * FROM orders "
                        "WHERE "
                        "created_at > ("
                        'CURRENT_DATE - INTERVAL "7 days"'
                        ")",
                        "source_config": {"uri": "${ORDERS_DB_URL}"},
                    },
                },
                "extract_products": {
                    "stage": "extract",
                    "component": "csv_extract",
                    "component_config": {
                        "source_config": {"path": "${PRODUCTS_CSV_PATH}"}
                    },
                },
                "transform_join_data": {
                    "stage": "transform",
                    "component": "json_transform",
                    "depends_on": ["extract_users", "extract_orders"],
                    "component_config": {
                        "join_config": {
                            "join_type": "inner",
                            "left_on": "user_id",
                            "right_on": "user_id",
                        },
                        "aggregation": {
                            "group_by": ["user_id"],
                            "aggregations": {
                                "order_value": "sum",
                                "order_count": "count",
                            },
                        },
                    },
                },
                "load_analytics": {
                    "stage": "load",
                    "component": "postgres_load",
                    "depends_on": ["transform_join_data"],
                    "component_config": {
                        "connection_config": {"uri": "${DWH_DATABASE_URL}"},
                        "target_table": "user_analytics",
                        "target_schema": "analytics",
                        "if_exists": "append",
                    },
                },
            },
            "required_env_vars": [
                "USERS_API_URL",
                "API_TOKEN",
                "ORDERS_DB_URL",
                "PRODUCTS_CSV_PATH",
                "DWH_DATABASE_URL",
            ],
            "max_parallel_stages": 3,
        },
    }

    template_config = templates.get(template, templates["simple"])
    output_path = output or Path(f"{name}.yml")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if (
        output_path.exists()
        and not force
        and not Confirm.ask(
            f"–§–∞–π–ª {output_path} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å?"
        )
    ):
        rprint("[yellow]–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ[/yellow]")
        return

    try:
        with open(output_path, "w", encoding="utf-8") as f:
            yaml.dump(
                template_config,
                f,
                default_flow_style=False,
                allow_unicode=True,
                indent=2,
            )

        rprint(
            f"‚úÖ –°–æ–∑–¥–∞–Ω —à–∞–±–ª–æ–Ω –ø–∞–π–ø–ª–∞–π–Ω–∞:"
            f"[bold green]{output_path}[/bold green]"
        )
        rprint(f"üìù –¢–∏–ø: [yellow]{template}[/yellow]")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        with open(output_path, encoding="utf-8") as f:
            content = f.read()

        syntax = Syntax(content, "yaml", theme="monokai", line_numbers=True)
        console.print(
            Panel(
                syntax, title=f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ {output_path}", border_style="blue"
            )
        )

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
        settings = chr(10).join(
            f'   export {var}="your_value"'
            for var in template_config.get("required_env_vars", [])
        )
        next_steps = f"""
[bold blue]–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:[/bold blue]

1. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
   {settings}

2. –í–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é:
   [cyan]temporal-pipeline pipeline validate {output_path}[/cyan]

3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–∞–π–ø–ª–∞–π–Ω:
   [cyan]temporal-pipeline pipeline run {output_path}[/cyan]

4. –ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤ dry-run —Ä–µ–∂–∏–º–µ:
   [cyan]temporal-pipeline pipeline run {output_path} --dry-run[/cyan]
"""

        console.print(
            Panel(next_steps, title="üöÄ –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã", border_style="green")
        )

        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if edit:
            import os
            import shutil
            import subprocess

            editor = os.environ.get("EDITOR", "nano")
            try:
                if shutil.which(editor):
                    subprocess.run([editor, str(output_path)], check=True)
            except Exception as ex:
                rprint(f"[yellow]–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ä–µ–¥–∞–∫—Ç–æ—Ä: {ex}[/yellow]")

    except Exception as ex:
        rprint(f"[red]‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —à–∞–±–ª–æ–Ω–∞: {ex}[/red]")
        raise typer.Exit(1) from ex


async def _start_worker_async(
    host: str,
    namespace: str,
    task_queue: str,
    max_activities: int,
    max_workflows: int,
) -> None:
    """–ó–∞–ø—É—Å–∫ Temporal Worker"""
    try:
        rprint(f"üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Temporal: [bold blue]{host}[/bold blue]")
        rprint(f"üìç Namespace: [bold yellow]{namespace}[/bold yellow]")
        rprint(f"üìã Task Queue: [bold green]{task_queue}[/bold green]")

        from temporalio.client import Client
        from temporalio.contrib.pydantic import pydantic_data_converter

        client = await Client.connect(
            host, namespace=namespace, data_converter=pydantic_data_converter
        )

        rprint("‚úÖ [bold green]–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Temporal —É—Å–ø–µ—à–Ω–æ![/bold green]")

        from core.component import PluginRegistry

        registry = PluginRegistry()
        await registry.initialize()

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        rprint("üì¶ –ò–º–ø–æ—Ä—Ç workflow –∏ activities...")

        try:
            rprint("‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
        except ImportError as ex:
            rprint(f"[red]‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {ex}[/red]")
            raise typer.Exit(1) from ex

        # –°–æ–∑–¥–∞–µ–º –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Worker
        from temporalio.worker import Worker

        rprint("‚öôÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ Worker...")
        rprint(f"   ‚Ä¢ –ú–∞–∫—Å. activities: {max_activities}")
        rprint(f"   ‚Ä¢ –ú–∞–∫—Å. workflows: {max_workflows}")

        worker = Worker(
            client,
            task_queue=task_queue,
            workflows=[DataPipelineWorkflow, ScheduledPipelineWorkflow],
            activities=[
                execute_stage_activity,
                validate_pipeline_activity,
                cleanup_pipeline_data_activity,
            ],
            max_concurrent_activities=max_activities,
            max_concurrent_workflow_tasks=max_workflows,
        )

        rprint("\nüéâ [bold green]Worker –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ![/bold green]")

        worker_info = f"""
[bold blue]–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ Worker:[/bold blue]

üñ•Ô∏è  Host: {host}
üìç Namespace: {namespace}
üìã Task Queue: {task_queue}
‚ö° –ú–∞–∫—Å. activities: {max_activities}
üîÑ –ú–∞–∫—Å. workflows: {max_workflows}

[bold green]Worker –æ–∂–∏–¥–∞–µ—Ç –∑–∞–¥–∞—á...[/bold green]
[dim]–ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏[/dim]
"""

        console.print(
            Panel(worker_info, title="‚öôÔ∏è Temporal Worker", border_style="blue")
        )

        # –ó–∞–ø—É—Å–∫–∞–µ–º Worker
        await worker.run()

    except KeyboardInterrupt:
        rprint("\nüõë [yellow]Worker –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º[/yellow]")
    except Exception as ex:
        rprint(f"\n‚ùå [bold red]–û—à–∏–±–∫–∞ Worker:[/bold red] {ex}")
        import traceback

        rprint(f"[dim]{traceback.format_exc()}[/dim]")
        raise typer.Exit(1) from ex


if __name__ == "__main__":
    app()
